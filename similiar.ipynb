{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing the number of ...   \n",
       "1  rap boss arrested over drug find rap mogul mar...   \n",
       "2  player burn-out worries robinson england coach...   \n",
       "3  hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4  sir paul rocks super bowl crowds sir paul mcca...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double in glasgow britain s jaso...  \n",
       "1  amnesty chief laments war failure the lack of ...  \n",
       "2  hanks greeted at wintry premiere hollywood sta...  \n",
       "3  redford s vision of sundance despite sporting ...  \n",
       "4  mauresmo opens with victory in la amelie maure...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"DataNeuron_Text_Similarity.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1277</td>\n",
       "      <td>1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>stars pay tribute to actor davis hollywood sta...</td>\n",
       "      <td>edwards tips idowu for euro gold world outdoor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text1  \\\n",
       "count                                                3000   \n",
       "unique                                               1277   \n",
       "top     stars pay tribute to actor davis hollywood sta...   \n",
       "freq                                                    9   \n",
       "\n",
       "                                                    text2  \n",
       "count                                                3000  \n",
       "unique                                               1256  \n",
       "top     edwards tips idowu for euro gold world outdoor...  \n",
       "freq                                                   12  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text1   3000 non-null   object\n",
      " 1   text2   3000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text1    0\n",
       "text2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text1']=df['text1'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text2']=df['text2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>uk directors guild nominees named martin scors...</td>\n",
       "      <td>steel firm  to cut  45 000 jobs mittal steel  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>u2 to play at grammy awards show irish rock ba...</td>\n",
       "      <td>israel looks to us for bank chief israel has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>pountney handed ban and fine northampton coach...</td>\n",
       "      <td>india and iran in gas export deal india has si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>belle named  best scottish band  belle &amp; sebas...</td>\n",
       "      <td>mido makes third apology ahmed  mido  hossam h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>criminal probe on citigroup deals traders at u...</td>\n",
       "      <td>former ni minister scott dies former northern ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0     broadband challenges tv viewing the number of ...   \n",
       "1     rap boss arrested over drug find rap mogul mar...   \n",
       "2     player burn-out worries robinson england coach...   \n",
       "3     hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4     sir paul rocks super bowl crowds sir paul mcca...   \n",
       "...                                                 ...   \n",
       "2995  uk directors guild nominees named martin scors...   \n",
       "2996  u2 to play at grammy awards show irish rock ba...   \n",
       "2997  pountney handed ban and fine northampton coach...   \n",
       "2998  belle named  best scottish band  belle & sebas...   \n",
       "2999  criminal probe on citigroup deals traders at u...   \n",
       "\n",
       "                                                  text2  \n",
       "0     gardener wins double in glasgow britain s jaso...  \n",
       "1     amnesty chief laments war failure the lack of ...  \n",
       "2     hanks greeted at wintry premiere hollywood sta...  \n",
       "3     redford s vision of sundance despite sporting ...  \n",
       "4     mauresmo opens with victory in la amelie maure...  \n",
       "...                                                 ...  \n",
       "2995  steel firm  to cut  45 000 jobs mittal steel  ...  \n",
       "2996  israel looks to us for bank chief israel has a...  \n",
       "2997  india and iran in gas export deal india has si...  \n",
       "2998  mido makes third apology ahmed  mido  hossam h...  \n",
       "2999  former ni minister scott dies former northern ...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gardener wins double in glasgow britain s jason gardener enjoyed a double 60m success in glasgow in his first competitive outing since he won 100m relay gold at the athens olympics.  gardener cruised home ahead of scot nick smith to win the invitational race at the norwich union international. he then recovered from a poor start in the second race to beat swede daniel persson and italy s luca verdecchia. his times of 6.61 and 6.62 seconds were well short of american maurice greene s 60m world record of 6.39secs from 1998.  it s a very hard record to break  but i believe i ve trained very well   said the world indoor champion  who hopes to get closer to the mark this season.  it was important to come out and make sure i got maximum points. my last race was the olympic final and there was a lot of expectation.  this was just what i needed to sharpen up and get some race fitness. i m very excited about the next couple of months.   double olympic champion  marked her first appearance on home soil since winning 1500m and 800m gold in athens with a victory. there was a third success for britain when  edged out russia s olga fedorova and sweden s jenny kallur to win the women s 60m race in 7.23secs. maduaka was unable to repeat the feat in the 200m  finishing down in fourth as  took the win for russia. and the 31-year-old also missed out on a podium place in the 4x200m relay as the british quartet came in fourth  with russia setting a new world indoor record. there was a setback for jade johnson as she suffered a recurrence of her back injury in the long jump. russia won the meeting with a final total of 63 points  with britain second on 48 and france one point behind in third.  led the way for russia by producing a major shock in the high jump as he beat olympic champion stefan holm into second place to end the swede s 22-event unbeaten record.  won the triple jump with a leap of 16.87m  with britain s tosin oke fourth in 15.80m.  won the men s pole vault competition with a clearance of 5.65m  with britain s nick buckfield 51cm adrift of his personal best in third. and  won the women s 800m  with britain s jenny meadows third. there was yet another russian victory in the women s 400m as  finished well clear of britain s catherine murphy. chris lambert had to settle for fourth after fading in the closing stages of the men s 200m race as sweden s  held off leslie djhone of france. france s  won the men s 400m  with brett rund fourth for britain.  took victory for sweden in the women s 60m hurdles ahead of russia s irina shevchenko and britain s sarah claxton  who set a new personal best. italy grabbed their first victory in the men s 1500m as  kicked over the last 200 metres to hold off britain s james thie and france s alexis abraham. a botched changeover in the 4x200m relay cost britain s men the chance to add further points as france claimed victory.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text1', 'text2'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\TASK SIMILIARITY\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "a:\\TASK SIMILIARITY\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vicky kumar\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_embeddings = model.encode(df['text1'].tolist(), convert_to_tensor=True)\n",
    "text2_embeddings = model.encode(df['text2'].tolist(), convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0251, -0.1229,  0.0115,  ..., -0.0723, -0.0583,  0.0373],\n",
      "        [ 0.0221,  0.0017, -0.1483,  ..., -0.0583,  0.0943, -0.0466],\n",
      "        [-0.0492,  0.0711,  0.0267,  ..., -0.1078,  0.0378,  0.0261],\n",
      "        ...,\n",
      "        [ 0.0045,  0.0351, -0.0005,  ..., -0.0300,  0.0134, -0.0492],\n",
      "        [-0.0428, -0.0857, -0.0002,  ..., -0.1155,  0.0483,  0.0072],\n",
      "        [-0.0908, -0.0040, -0.0576,  ..., -0.1005, -0.0066,  0.0306]])\n"
     ]
    }
   ],
   "source": [
    "print(text1_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0382,  0.0024, -0.0259,  ..., -0.1191, -0.0926,  0.0380],\n",
      "        [-0.0966,  0.0913, -0.0786,  ..., -0.0400, -0.0382,  0.0013],\n",
      "        [-0.0504,  0.0819, -0.0460,  ...,  0.0247,  0.0017,  0.0653],\n",
      "        ...,\n",
      "        [-0.0782, -0.0102, -0.0039,  ..., -0.0317,  0.0285,  0.0214],\n",
      "        [-0.0247,  0.1061,  0.0875,  ...,  0.0319, -0.0726, -0.0318],\n",
      "        [ 0.0767, -0.0574, -0.0669,  ..., -0.0389, -0.0418, -0.0441]])\n"
     ]
    }
   ],
   "source": [
    "print(text2_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(text1_embeddings.cpu().numpy(), text2_embeddings.cpu().numpy())\n",
    "\n",
    "# Extract diagonal values (pairwise similarity)\n",
    "df['similarity_score'] = [similarities[i, i] for i in range(len(df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity: -0.0654\n"
     ]
    }
   ],
   "source": [
    "def compute_similarity(text1, text2, model):\n",
    "    text1_embedding = model.encode([text1], convert_to_tensor=True)\n",
    "    text2_embedding = model.encode([text2], convert_to_tensor=True)\n",
    "    \n",
    "    similarity = cosine_similarity(text1_embedding.cpu().numpy(), text2_embedding.cpu().numpy())\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Example\n",
    "similarity_score = compute_similarity(\"nuclear body seeks new tech .\", \"terror suspectsface arrest\", model)\n",
    "print(f\"Semantic Similarity: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity: 0.5431\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_similarity(text1, text2, model):\n",
    "    text1_embedding = model.encode([text1], convert_to_tensor=True)\n",
    "    text2_embedding = model.encode([text2], convert_to_tensor=True)\n",
    "    \n",
    "    similarity = cosine_similarity(text1_embedding.cpu().numpy(), text2_embedding.cpu().numpy())[0][0]\n",
    "    \n",
    "    # Normalize similarity to be between 0 and 1\n",
    "    normalized_similarity = (similarity + 1) / 2\n",
    "    return normalized_similarity\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Example\n",
    "similarity_score = compute_similarity(\n",
    "'broadband challenges tv viewing the number of europeans with broadband has exploded over the past 12 months  with the web eating into tv viewing habits  research suggests.  just over 54 million people are hooked up to the net via broadband  up from 34 million a year ago  according to market analysts nielsen/netratings. the total number of people online in europe has broken the 100 million mark. the popularity of the net has meant that many are turning away from tv  say analysts jupiter research. it found that a quarter of web users said they spent less time watching tv in favour of the net  the report by nielsen/netratings found that the number of people with fast internet access had risen by 60% over the past year.  the biggest jump was in italy  where it rose by 120%. britain was close behind  with broadband users almost doubling in a year. the growth has been fuelled by lower prices and a wider choice of always-on  fast-net subscription plans.  twelve months ago high speed internet users made up just over one third of the audience in europe; now they are more than 50% and we expect this number to keep growing   said gabrielle prior  nielsen/netratings analyst.  as the number of high-speed surfers grows  websites will need to adapt  update and enhance their content to retain their visitors and encourage new ones.  the total number of europeans online rose by 12% to 100 million over the past year  the report showed  with the biggest rise in france  italy  britain and germany.  the ability to browse web pages at high speed  download files such as music or films and play online games is changing what people do in their spare time.  a study by analysts jupiter research suggested that broadband was challenging television viewing habits. in homes with broadband  40% said they were spending less time watching tv. the threat to tv was greatest in countries where broadband was on the up  in particular the uk  france and spain  said the report. it said tv companies faced a major long-term threat over the next five years  with broadband predicted to grow from 19% to 37% of households by 2009.  year-on-year we are continuing to see a seismic shift in where  when and how europe s population consume media for information and entertainment and this has big implications for tv  newspaper and radio   said jupiter research analyst olivier beauvillian.', \n",
    "'gardener wins double in glasgow britain s jason gardener enjoyed a double 60m success in glasgow in his first competitive outing since he won 100m relay gold at the athens olympics.  gardener cruised home ahead of scot nick smith to win the invitational race at the norwich union international. he then recovered from a poor start in the second race to beat swede daniel persson and italy s luca verdecchia. his times of 6.61 and 6.62 seconds were well short of american maurice greene s 60m world record of 6.39secs from 1998.  it s a very hard record to break  but i believe i ve trained very well   said the world indoor champion  who hopes to get closer to the mark this season.  it was important to come out and make sure i got maximum points. my last race was the olympic final and there was a lot of expectation.  this was just what i needed to sharpen up and get some race fitness. i m very excited about the next couple of months.   double olympic champion  marked her first appearance on home soil since winning 1500m and 800m gold in athens with a victory. there was a third success for britain when  edged out russia s olga fedorova and sweden s jenny kallur to win the women s 60m race in 7.23secs. maduaka was unable to repeat the feat in the 200m  finishing down in fourth as  took the win for russia. and the 31-year-old also missed out on a podium place in the 4x200m relay as the british quartet came in fourth  with russia setting a new world indoor record. there was a setback for jade johnson as she suffered a recurrence of her back injury in the long jump. russia won the meeting with a final total of 63 points  with britain second on 48 and france one point behind in third.  led the way for russia by producing a major shock in the high jump as he beat olympic champion stefan holm into second place to end the swede s 22-event unbeaten record.  won the triple jump with a leap of 16.87m  with britain s tosin oke fourth in 15.80m.  won the men s pole vault competition with a clearance of 5.65m  with britain s nick buckfield 51cm adrift of his personal best in third. and  won the women s 800m  with britain s jenny meadows third. there was yet another russian victory in the women s 400m as  finished well clear of britain s catherine murphy. chris lambert had to settle for fourth after fading in the closing stages of the men s 200m race as sweden s  held off leslie djhone of france. france s  won the men s 400m  with brett rund fourth for britain.  took victory for sweden in the women s 60m hurdles ahead of russia s irina shevchenko and britain s sarah claxton  who set a new personal best. italy grabbed their first victory in the men s 1500m as  kicked over the last 200 metres to hold off britain s james thie and france s alexis abraham. a botched changeover in the 4x200m relay cost britain s men the chance to add further points as france claimed victory.'    \n",
    "    , model)\n",
    "print(f\"Semantic Similarity: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordllama import WordLlama\n",
    "\n",
    "class WordLlamaController:\n",
    "    def __init__(self):\n",
    "        self.model = WordLlama()  # Initialize WordLlama\n",
    "\n",
    "    def compute_similarity(self, text1: str, text2: str):\n",
    "        \"\"\"Check available methods in WordLlama\"\"\"\n",
    "        print(dir(self.model))  # Print available methods\n",
    "        return self.model.similarity(text1, text2)  # Might need correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'compute_similarity']\n"
     ]
    }
   ],
   "source": [
    "print(dir(WordLlamaController))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.025584951043128967\n"
     ]
    }
   ],
   "source": [
    "from wordllama import WordLlama\n",
    "\n",
    "# Load the default WordLlama model\n",
    "wl = WordLlama.load()\n",
    "\n",
    "# Define your texts\n",
    "text1 = \"\"\"broadband challenges tv viewing the number of europeans with broadband has exploded over the past 12 months \n",
    "with the web eating into tv viewing habits research suggests. just over 54 million people are hooked up to the net \n",
    "via broadband up from 34 million a year ago according to market analysts nielsen/netratings. the total number of \n",
    "people online in europe has broken the 100 million mark. the popularity of the net has meant that many are turning \n",
    "away from tv say analysts jupiter research.\"\"\"\n",
    "\n",
    "text2 = \"\"\"gardener wins double in glasgow britain s jason gardener enjoyed a double 60m success in glasgow in his first \n",
    "competitive outing since he won 100m relay gold at the athens olympics. gardener cruised home ahead of scot nick smith \n",
    "to win the invitational race at the norwich union international.\"\"\"\n",
    "\n",
    "# Compute similarity\n",
    "similarity_score = wl.similarity(text1, text2)\n",
    "\n",
    "# Print result\n",
    "print(\"Similarity Score:\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Similarity Score: 0.5959986448287964\n",
      "Normalized Score (0 to 1): 0.6447\n"
     ]
    }
   ],
   "source": [
    "from wordllama import WordLlama\n",
    "import numpy as np  # For sigmoid function\n",
    "\n",
    "# Load the model\n",
    "wl = WordLlama.load()\n",
    "\n",
    "# Define your texts\n",
    "text1 = \"\"\"I love you \"\"\"\n",
    "\n",
    "text2 = \"\"\"you are loved by me.\"\"\"\n",
    "\n",
    "# Compute raw similarity score\n",
    "raw_score = wl.similarity(text1, text2)\n",
    "\n",
    "# Normalize using sigmoid to bring it between 0 and 1\n",
    "normalized_score = 1 / (1 + np.exp(-raw_score))\n",
    "\n",
    "# Print results\n",
    "print(f\"Raw Similarity Score: {raw_score}\")\n",
    "print(f\"Normalized Score (0 to 1): {normalized_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\TASK SIMILIARITY\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vicky kumar\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Textual Similarity Model Loaded.\n",
      "Similarity Score: 0.8604\n",
      "\n",
      "Similarity Score: 0.2810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Get the appropriate device (CPU or CUDA) based on availability.\"\"\"\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    \"\"\"Perform mean pooling on token embeddings.\"\"\"\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "class STSModel:\n",
    "    \"\"\"Semantic Textual Similarity Model using Transformer-based embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-mpnet-base-v2\"):\n",
    "        self.device = get_device()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def encode(self, texts):\n",
    "        \"\"\"Generate embeddings for the input text(s).\"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        inputs = self.tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return mean_pooling(outputs, inputs['attention_mask']).cpu().numpy()\n",
    "    \n",
    "    def compute_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"Compute the semantic similarity between two texts.\"\"\"\n",
    "        embeddings = self.encode([text1, text2])\n",
    "        return float(cosine_similarity(embeddings[0], embeddings[1]))\n",
    "\n",
    "def main():\n",
    "    \"\"\"Command-line interface to test the similarity model.\"\"\"\n",
    "    model = STSModel()\n",
    "    print(\"Semantic Textual Similarity Model Loaded.\")\n",
    "    \n",
    "    while True:\n",
    "        text1 = input(\"Enter first text (or 'exit' to quit): \")\n",
    "        if text1.lower() == 'exit':\n",
    "            break\n",
    "        text2 = input(\"Enter second text: \")\n",
    "        similarity = model.compute_similarity(text1, text2)\n",
    "        print(f\"Similarity Score: {similarity:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
